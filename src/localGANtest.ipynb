{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Xv-YpA9CmI",
        "outputId": "08b45be8-4ba6-49d4-93e0-4971f5d9e1b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/25] [0/14] D_loss: 1.4899190664291382 | G_loss: 1.8973863124847412\n",
            "[0/25] [5/14] D_loss: 0.00783935934305191 | G_loss: 9.400535583496094\n",
            "[0/25] [10/14] D_loss: 0.002823860850185156 | G_loss: 11.908961296081543\n",
            "[1/25] [0/14] D_loss: 0.009661608375608921 | G_loss: 12.882421493530273\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import requests\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def download_xray_dataset(url, save_path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in response.iter_content(chunk_size=128):\n",
        "            fd.write(chunk)\n",
        "\n",
        "# Uncomment the following to download the dataset\n",
        "'''download_xray_dataset('https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz', 'data_part1.tar.gz')\n",
        "\n",
        "# Assuming you've downloaded all parts and they are named as 'data_part1.tar.gz', 'data_part2.tar.gz', etc.\n",
        "# Extract them in the respective order.\n",
        "with tarfile.open('data_part1.tar.gz', 'r:gz') as tar:\n",
        "    tar.extractall('./data')\n",
        "'''\n",
        "\n",
        "if not os.path.exists('./data/images/real_images'):\n",
        "    os.makedirs('./data/images/real_images')\n",
        "\n",
        "    for img_file in os.listdir('./data/images'):\n",
        "        if img_file.endswith('.png'):\n",
        "            shutil.move(os.path.join('./data/images', img_file), './data/images/real_images')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # You might need to change this depending on your GAN architecture\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(root='./data/images', transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64*6, shuffle=True)\n",
        "\n",
        "class ResidualBlockUp(nn.Module):\n",
        "    \"\"\" Upsampling Residual Block \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlockUp, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 3, stride=stride, padding=1, output_padding=stride-1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=1, stride=stride, output_padding=stride-1),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.main(x) + self.shortcut(x))\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0),  # 4x4\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            ResidualBlockUp(512, 256, stride=2),  # 8x8\n",
        "\n",
        "            ResidualBlockUp(256, 128, stride=2),  # 16x16\n",
        "\n",
        "            ResidualBlockUp(128, 64, stride=2),   # 32x32\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1),   # 64x64\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),  # 32x32\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),  # 16x16\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),  # 8x8\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),  # 4x4\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512*4*4, 1),\n",
        "\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).squeeze()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "\n",
        "# Loss and Optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 25\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        # (1) Update Discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "\n",
        "        ## Train with real images\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        real_images = data[0].to(device)\n",
        "        b_size = real_images.size(0)\n",
        "        labels = torch.full((b_size,), 1, device=device, dtype=torch.float)\n",
        "\n",
        "\n",
        "        output = discriminator(real_images).view(-1)\n",
        "        d_loss_real = criterion(output, labels)\n",
        "        d_loss_real.backward()\n",
        "\n",
        "        ## Train with fake images\n",
        "        noise = torch.randn(b_size, 100, 1, 1).to(device)\n",
        "        fake_images = generator(noise).detach()\n",
        "        labels.fill_(0)\n",
        "\n",
        "        output = discriminator(fake_images.detach()).view(-1)\n",
        "        d_loss_fake = criterion(output, labels)\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # (2) Update Generator: maximize log(D(G(z)))\n",
        "        generator.zero_grad()\n",
        "        labels.fill_(1)\n",
        "\n",
        "        output = discriminator(fake_images).view(-1)\n",
        "        g_loss = criterion(output, labels)\n",
        "        g_loss.backward()\n",
        "\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Print stats\n",
        "        if i % 5 == 0:\n",
        "            print(f\"[{epoch}/{num_epochs}] [{i}/{len(dataloader)}] D_loss: {d_loss.item()} | G_loss: {g_loss.item()}\")\n",
        "\n",
        "        # Save losses for plotting later\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "    # Save generator's output after each epoch\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(noise).detach().cpu()\n",
        "    img_list.append(torchvision.utils.make_grid(fake_images, padding=2, normalize=True))\n",
        "\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Visualize the GAN's progression (last epoch result)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1,2,0)))\n",
        "plt.show()\n"
      ]
    }
  ]
}