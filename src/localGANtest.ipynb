{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Xv-YpA9CmI",
        "outputId": "3984ea44-1758-47f0-d6a2-a223f9edec03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/25] [0/157] D_loss: -5.014007911086082e-07 | G_loss: -0.000841793604195118\n",
            "[0/25] [5/157] D_loss: -0.068069227039814 | G_loss: 0.16241255402565002\n",
            "[0/25] [10/157] D_loss: -435.67022705078125 | G_loss: 546.9578857421875\n",
            "[0/25] [15/157] D_loss: -209.1055450439453 | G_loss: 247.42147827148438\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import requests\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def download_xray_dataset(url, save_path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in response.iter_content(chunk_size=128):\n",
        "            fd.write(chunk)\n",
        "\n",
        "def extract_dataset(filename):\n",
        "    with tarfile.open(filename, 'r:gz') as tar:\n",
        "        tar.extractall('./data')\n",
        "\n",
        "# List of datasets URLs. Add or modify based on your needs.\n",
        "dataset_urls = [\n",
        "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
        "    # Add more URLs here...\n",
        "]\n",
        "\n",
        "# Download and extract each dataset\n",
        "for url in dataset_urls:\n",
        "    dataset_file = url.split(\"/\")[-1]  # Extracts 'data_part1.tar.gz' from the URL for instance\n",
        "    if not os.path.exists(dataset_file):\n",
        "        download_xray_dataset(url, dataset_file)\n",
        "        extract_dataset(dataset_file)\n",
        "\n",
        "if not os.path.exists('./data/images/real_images'):\n",
        "    os.makedirs('./data/images/real_images')\n",
        "\n",
        "# Move all the images to the 'real_images' directory\n",
        "for img_file in os.listdir('./data/images'):\n",
        "    if img_file.endswith('.png'):\n",
        "        shutil.move(os.path.join('./data/images', img_file), './data/images/real_images')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((1024, 1024)),  # You might need to change this depending on your GAN architecture\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(root='./data/images', transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Weight clipping function to be used later during training\n",
        "def weight_clipping(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        m.weight.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "class ResidualBlockUp(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=2):\n",
        "        super(ResidualBlockUp, self).__init__()\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 4, stride=stride, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, 4, stride=stride, padding=1, output_padding=1),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.main(x) + self.shortcut(x))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 1024, 4, 1, 0),  # 4x4\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            ResidualBlockUp(1024, 512, stride=2),  # 8x8\n",
        "            ResidualBlockUp(512, 256, stride=2),  # 16x16\n",
        "            ResidualBlockUp(256, 128, stride=2),  # 32x32\n",
        "            ResidualBlockUp(128, 64, stride=2),   # 64x64\n",
        "            ResidualBlockUp(64, 32, stride=2),    # 128x128\n",
        "            ResidualBlockUp(32, 16, stride=2),    # 256x256\n",
        "            ResidualBlockUp(16, 8, stride=2),     # 512x512\n",
        "\n",
        "            nn.ConvTranspose2d(8, 1, 4, 2, 1),    # 1024x1024\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 4, 2, 1, bias=False),  # 512x512\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(4, 8, 4, 2, 1, bias=False),  # 256x256\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(8, 16, 4, 2, 1, bias=False), # 128x128\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(16, 32, 4, 2, 1, bias=False), # 64x64\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(32, 64, 4, 2, 1, bias=False), # 32x32\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False), # 16x16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False), # 8x8\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False), # 4x4\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512*4*4, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).squeeze()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "\n",
        "# Loss and Optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0005)\n",
        "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0005)\n",
        "\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 25\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        # Train the discriminator more often than the generator\n",
        "        for _ in range(5):\n",
        "            ## (1) Update Discriminator\n",
        "            discriminator.zero_grad()\n",
        "\n",
        "            real_images = data[0].to(device)\n",
        "            b_size = real_images.size(0)\n",
        "\n",
        "            # Loss for real images\n",
        "            d_loss_real = -torch.mean(discriminator(real_images))\n",
        "\n",
        "            # Loss for fake images\n",
        "            noise = torch.randn(b_size, 100, 1, 1).to(device)\n",
        "            fake_images = generator(noise)\n",
        "            d_loss_fake = torch.mean(discriminator(fake_images.detach()))\n",
        "\n",
        "            # Combined discriminator loss\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Weight clipping for the discriminator\n",
        "            discriminator.apply(weight_clipping)\n",
        "\n",
        "        ## (2) Update Generator\n",
        "        generator.zero_grad()\n",
        "\n",
        "        # Generator's loss\n",
        "        output = discriminator(fake_images)\n",
        "        g_loss = -torch.mean(output)\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Print stats\n",
        "        if i % 5 == 0:\n",
        "            print(f\"[{epoch}/{num_epochs}] [{i}/{len(dataloader)}] D_loss: {d_loss.item()} | G_loss: {g_loss.item()}\")\n",
        "\n",
        "        # Save losses for plotting later\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "    # Save and display generator's output after each epoch\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(noise).detach().cpu()\n",
        "    img_list.append(torchvision.utils.make_grid(fake_images, padding=2, normalize=True))\n",
        "\n",
        "    # Display the images\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Generated Images at Epoch {epoch}\")\n",
        "    plt.imshow(np.transpose(img_list[-1], (1,2,0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Visualize the GAN's progression (last epoch result)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1,2,0)))\n",
        "plt.show()\n"
      ]
    }
  ]
}